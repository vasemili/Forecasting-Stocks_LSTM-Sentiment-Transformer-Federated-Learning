{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c80bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182d9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "124/124 [==============================] - 10s 35ms/step - loss: 1.2911e-04\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 3.6946e-06\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 3.5464e-06\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 3.0766e-06\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 2.9285e-06\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 2.9491e-06\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 4s 35ms/step - loss: 2.7254e-06\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 2.5809e-06\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 4s 35ms/step - loss: 2.2872e-06\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 2.2756e-06\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 2.7509e-06\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 2.0945e-06\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 2.1611e-06\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 4s 28ms/step - loss: 1.8582e-06\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 2.0351e-06\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 2.0222e-06\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 5s 39ms/step - loss: 1.8382e-06\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 2.0358e-06\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 1.8733e-06\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 5s 38ms/step - loss: 2.0163e-06\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 5s 36ms/step - loss: 1.4906e-06\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 1.9270e-06\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 1.6119e-06\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 4s 34ms/step - loss: 4.4016e-06\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 1.4309e-06\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 1.4903e-06\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 5s 41ms/step - loss: 1.3674e-06\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 1.3612e-06\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 5s 40ms/step - loss: 1.3824e-06\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 1.4918e-06\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 5s 37ms/step - loss: 1.3084e-06\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.3349e-06\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 4s 29ms/step - loss: 1.3206e-06\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.4348e-06\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.5791e-06\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.3623e-06\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 4s 33ms/step - loss: 1.4051e-06\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.2796e-06\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.3356e-06\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.2610e-06\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.2702e-06\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.5711e-06\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 4s 31ms/step - loss: 1.4823e-06\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.2995e-06\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.3523e-06\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.1711e-06\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 3s 28ms/step - loss: 1.3075e-06\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 2.5509e-06\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 3s 27ms/step - loss: 1.6238e-06\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 4s 30ms/step - loss: 1.0597e-06\n",
      "34/34 [==============================] - 2s 9ms/step - loss: 0.0011\n",
      "Test Loss: 0.001139183295890689\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Forecast for the next 30 days: [[226.32043]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "\n",
    "# Remove the 'Date' column\n",
    "data = data.drop('Date', axis=1)\n",
    "\n",
    "# Normalize the data\n",
    "data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = data_norm[:2000]\n",
    "test_data = data_norm[2000:]\n",
    "\n",
    "# Function to prepare data for LSTM model\n",
    "def prepare_data(data, num_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - num_steps - 1):\n",
    "        X.append(data[i:(i + num_steps)].values)\n",
    "        y.append(data.iloc[i + num_steps]['Close'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare the training and testing data for the LSTM model\n",
    "num_steps = 30\n",
    "X_train, y_train = prepare_data(train_data, num_steps)\n",
    "X_test, y_test = prepare_data(test_data, num_steps)\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', test_loss)\n",
    "\n",
    "# Make predictions for the next 30 days\n",
    "last_30_days = data_norm[-30:].values.reshape(1, 30, 6)\n",
    "forecast = model.predict(last_30_days)\n",
    "forecast_denorm = (forecast * (data['Close'].max() - data['Close'].min())) + data['Close'].min()\n",
    "print('Forecast for the next 30 days:', forecast_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c8a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "95/95 [==============================] - 44s 256ms/step - loss: 0.0049\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 24s 252ms/step - loss: 0.0020\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 24s 253ms/step - loss: 0.0023\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.0024\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 23s 240ms/step - loss: 0.0016\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 22s 236ms/step - loss: 0.0017\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 22s 233ms/step - loss: 0.0013\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 24s 252ms/step - loss: 0.0014\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 25s 267ms/step - loss: 0.0013\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 28s 297ms/step - loss: 0.0012\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 26s 275ms/step - loss: 0.0010\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 21s 220ms/step - loss: 0.0012\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.0012\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.0011\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 11s 115ms/step - loss: 0.0012\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 12s 123ms/step - loss: 0.0011\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 12s 129ms/step - loss: 0.0010\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 12s 122ms/step - loss: 0.0013\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 12s 126ms/step - loss: 9.2047e-04\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 11s 110ms/step - loss: 9.0199e-04\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 11s 118ms/step - loss: 8.6594e-04\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 11s 118ms/step - loss: 9.1601e-04\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 11s 116ms/step - loss: 8.6356e-04\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 11s 118ms/step - loss: 9.0572e-04\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 12s 124ms/step - loss: 8.6637e-04\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 11s 121ms/step - loss: 8.8221e-04\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 12s 124ms/step - loss: 0.0010\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 11s 117ms/step - loss: 9.4823e-04\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 11s 114ms/step - loss: 9.2828e-04\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 11s 119ms/step - loss: 9.3626e-04\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 12s 126ms/step - loss: 7.8182e-04\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 12s 126ms/step - loss: 7.3410e-04\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 6.8439e-04\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 11s 117ms/step - loss: 7.5868e-04\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 12s 121ms/step - loss: 7.2440e-04\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 12s 125ms/step - loss: 7.0737e-04\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 7.3904e-04\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 12s 126ms/step - loss: 7.8928e-04\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 12s 123ms/step - loss: 7.9402e-04\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 12s 125ms/step - loss: 7.4920e-04\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 12s 129ms/step - loss: 8.1569e-04\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 11s 115ms/step - loss: 8.0404e-04\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 12s 130ms/step - loss: 7.1089e-04\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 11s 117ms/step - loss: 6.7649e-04\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 11s 119ms/step - loss: 7.7400e-04\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 11s 114ms/step - loss: 7.5289e-04\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 11s 116ms/step - loss: 7.7476e-04\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 11s 112ms/step - loss: 6.7732e-04\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 11s 119ms/step - loss: 6.9588e-04\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 11s 119ms/step - loss: 7.0499e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Make the predictions for the next 30 days\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m predicted_price_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m predicted_price \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39minverse_transform(predicted_price_scaled)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Plot the predicted prices for the next 30 days\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2278\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2274\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2275\u001b[0m                     end_step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2276\u001b[0m                 )\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2284\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2287\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2288\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2289\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Load the data from the csv file\n",
    "df = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "\n",
    "# Select the features to be used for training the model\n",
    "training_set = df.iloc[:, 1:-1].values\n",
    "\n",
    "# Scale the data between 0 and 1\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "# Define the number of time steps and features for the LSTM model\n",
    "timesteps = 60\n",
    "features = training_set_scaled.shape[1]\n",
    "\n",
    "# Create the training data with the defined timesteps\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(timesteps, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-timesteps:i, :])\n",
    "    y_train.append(training_set_scaled[i, 3])\n",
    "\n",
    "# Convert the training data to numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], features)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Create the test data\n",
    "test_set = df.iloc[-timesteps:, 1:-1].values\n",
    "test_set_scaled = sc.transform(test_set)\n",
    "\n",
    "# Create the test data with the defined timesteps\n",
    "X_test = []\n",
    "for i in range(timesteps, len(test_set_scaled)):\n",
    "    X_test.append(test_set_scaled[i-timesteps:i, :])\n",
    "\n",
    "# Convert the test data to a numpy array\n",
    "X_test = np.array(X_test)\n",
    "predicted_price_scaled = model.predict(X_test)\n",
    "predicted_price = sc.inverse_transform(predicted_price_scaled)\n",
    "\n",
    "# Plot the predicted prices for the next 30 days\n",
    "plt.plot(predicted_price, label='Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Amazon Stock Price Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda4c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 7s 42ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3090,1) doesn't match the broadcast shape (3090,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test)\n\u001b[0;32m      8\u001b[0m predicted_price_scaled \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> 9\u001b[0m predicted_price \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_price_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Plot the predicted prices for the next 30 days\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(predicted_price, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:529\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    523\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    525\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    526\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m )\n\u001b[1;32m--> 529\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    530\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (3090,1) doesn't match the broadcast shape (3090,5)"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Importing the training set\n",
    "dataset_train = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "training_set = dataset_train.iloc[:, 1:-1].values\n",
    "\n",
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(training_set)):\n",
    "    X_train.append(training_set_scaled[i-60:i, :])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# Building the LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the LSTM\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the LSTM to the Training set\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 32)\n",
    "\n",
    "# Getting the real stock price of 2022\n",
    "dataset_test = pd.read_csv('AMZN_test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1].values\n",
    "\n",
    "# Getting the predicted stock price of 2022\n",
    "dataset_total = pd.concat((dataset_train.iloc[:, 1:-1], dataset_test.iloc[:, 1:-1]), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 60+len(dataset_test)):\n",
    "    X_test.append(inputs[i-60:i, :])\n",
    "X_test = np.array(X_test)\n",
    "predicted_price_scaled = model.predict(X_test)\n",
    "predicted_price = sc.inverse_transform(predicted_price_scaled)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Amazon Stock Price')\n",
    "plt.plot(predicted_price, color = 'blue', label = 'Predicted Amazon Stock Price')\n",
    "plt.title('Amazon Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amazon Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53f2f0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "76/76 [==============================] - 11s 55ms/step - loss: 0.0036\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 6.1962e-04\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 4.9331e-04\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 4.8585e-04\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 3.9141e-04\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 4.4030e-04\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 3.9912e-04\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 3.8816e-04\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 4.0531e-04\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 3s 44ms/step - loss: 3.4043e-04\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 3.2213e-04\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 3.1222e-04\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 3.0780e-04\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 2.9282e-04\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 5s 62ms/step - loss: 2.6629e-04\n",
      "Epoch 16/50\n",
      "76/76 [==============================] - 4s 48ms/step - loss: 2.5754e-04\n",
      "Epoch 17/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 2.6789e-04\n",
      "Epoch 18/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 2.8000e-04\n",
      "Epoch 19/50\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 2.5368e-04\n",
      "Epoch 20/50\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 2.4115e-04\n",
      "Epoch 21/50\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 2.3835e-04\n",
      "Epoch 22/50\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 2.1532e-04\n",
      "Epoch 23/50\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 2.1144e-04\n",
      "Epoch 24/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.8709e-04\n",
      "Epoch 25/50\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 2.1029e-04\n",
      "Epoch 26/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.8931e-04\n",
      "Epoch 27/50\n",
      "76/76 [==============================] - 4s 59ms/step - loss: 1.6492e-04\n",
      "Epoch 28/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.7290e-04\n",
      "Epoch 29/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.6719e-04\n",
      "Epoch 30/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.5487e-04\n",
      "Epoch 31/50\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 1.6042e-04\n",
      "Epoch 32/50\n",
      "76/76 [==============================] - 4s 59ms/step - loss: 1.6061e-04\n",
      "Epoch 33/50\n",
      "76/76 [==============================] - 5s 60ms/step - loss: 1.7209e-04\n",
      "Epoch 34/50\n",
      "76/76 [==============================] - 5s 61ms/step - loss: 1.8597e-04\n",
      "Epoch 35/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.5208e-04\n",
      "Epoch 36/50\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 1.6783e-04\n",
      "Epoch 37/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.7527e-04\n",
      "Epoch 38/50\n",
      "76/76 [==============================] - 4s 53ms/step - loss: 1.5662e-04\n",
      "Epoch 39/50\n",
      "76/76 [==============================] - 4s 56ms/step - loss: 1.4620e-04\n",
      "Epoch 40/50\n",
      "76/76 [==============================] - 4s 52ms/step - loss: 1.6976e-04\n",
      "Epoch 41/50\n",
      "76/76 [==============================] - 4s 50ms/step - loss: 1.7300e-04\n",
      "Epoch 42/50\n",
      "76/76 [==============================] - 4s 59ms/step - loss: 1.8411e-04\n",
      "Epoch 43/50\n",
      "76/76 [==============================] - 4s 54ms/step - loss: 1.4913e-04\n",
      "Epoch 44/50\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 1.4645e-04\n",
      "Epoch 45/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.5229e-04\n",
      "Epoch 46/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.7078e-04\n",
      "Epoch 47/50\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 1.5640e-04\n",
      "Epoch 48/50\n",
      "76/76 [==============================] - 4s 58ms/step - loss: 1.6851e-04\n",
      "Epoch 49/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.7194e-04\n",
      "Epoch 50/50\n",
      "76/76 [==============================] - 4s 57ms/step - loss: 1.5434e-04\n",
      "93/93 [==============================] - 3s 24ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3030,1) doesn't match the broadcast shape (3030,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m predicted_price_scaled \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_combined)\n\u001b[0;32m     52\u001b[0m predicted_price_scaled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m1\u001b[39m)), predicted_price_scaled), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m predicted_price \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_price_scaled\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# plot the actual and predicted closing prices\u001b[39;00m\n\u001b[0;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Price\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:529\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    523\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    525\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    526\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m )\n\u001b[1;32m--> 529\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    530\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (3030,1) doesn't match the broadcast shape (3030,6)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "\n",
    "# keep only the relevant columns\n",
    "df = df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "\n",
    "# split the data into train and test sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df.iloc[:train_size].values\n",
    "test_data = df.iloc[train_size:].values\n",
    "\n",
    "# normalize the data\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_scaled = sc.fit_transform(train_data)\n",
    "test_data_scaled = sc.transform(test_data)\n",
    "\n",
    "# create the training and testing data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, train_size):\n",
    "    X_train.append(train_data_scaled[i-60:i, :])\n",
    "    y_train.append(train_data_scaled[i, 3])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60, len(test_data)):\n",
    "    X_test.append(test_data_scaled[i-60:i, :])\n",
    "    y_test.append(test_data_scaled[i, 3])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# compile and fit the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# generate predictions\n",
    "X_combined = np.concatenate((X_train, X_test), axis=0)\n",
    "predicted_price_scaled = model.predict(X_combined)\n",
    "predicted_price_scaled = np.concatenate((np.zeros((60, 1)), predicted_price_scaled), axis=0)\n",
    "predicted_price = sc.inverse_transform(predicted_price_scaled)[:, 0]\n",
    "\n",
    "# plot the actual and predicted closing prices\n",
    "plt.plot(df['Close'], label='Actual Price')\n",
    "plt.plot(predicted_price, label='Predicted Price')\n",
    "plt.title('30 Day Forecast')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a937f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 13s 100ms/step - loss: 0.2499\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.1274\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0616\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0280\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0477\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0220\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0185\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0236\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0162\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0145\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0212\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0226\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0144\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0175\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0207\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0165\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0134\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0164\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0145\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0194\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0170\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0149\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0159\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0166\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0115\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0126\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0149\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0114\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0147\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0179\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0126\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0132\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0101\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0109\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0083\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0106\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0117\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0114\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0119\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0103\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0077\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0080\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0083\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0049\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0074\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0088\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0078\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0075\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0078\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0063\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0054\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0067\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0087\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0045\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0082\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0094\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0068\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0053\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0066\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0071\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0071\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0067\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0068\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0058\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0089\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0067\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0067\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0065\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0077\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0050\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0055\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0061\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0055\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0068\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0068\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0032\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0038\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0063\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0090\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0062\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0054\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0056\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0050\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0056\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0064\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0048\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0062\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0074\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0069\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0066\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0078\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0043\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0045\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0040\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0036\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0052\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0068\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0054\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0048\n",
      "WARNING:tensorflow:6 out of the last 98 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F4D19CEB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "df = df.drop(labels=range(0, len(df.index)-30), axis=0) #127\n",
    "df = df.reset_index()\n",
    "df_date_test = df['Date']\n",
    "df_date_test.index = pd.to_datetime(df['Date']);\n",
    "df_date_test\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "df = df.drop(labels=range(0, len(df.index)-127), axis=0) #127\n",
    "df = df.reset_index()\n",
    "df = df.drop(labels=range(len(df.index)-30, len(df.index)), axis=0) #127\n",
    "df_date_train = df['Date']\n",
    "df_date_train.index = pd.to_datetime(df['Date']);\n",
    "df_date_train\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\emili\\Downloads\\Machine_Learning_SP_Course\\Machine_Learning_Project\\TSLA.csv')\n",
    "df = df.drop(labels=range(0, len(df.index)-127), axis=0) #127\n",
    "df_date['Date'] = pd.to_datetime(df['Date']);\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "training_set = df.iloc[:len(df)-30, 1:7].values\n",
    "testing_set = df.iloc[len(df)-30:, 1:7].values\n",
    "\n",
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(training_set)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0:6])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 6))\n",
    "\n",
    "# Initializing the RNN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 6)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Making the predictions\n",
    "dataset_total = df.iloc[:, 1:7]\n",
    "inputs = dataset_total[len(dataset_total)-len(testing_set)-60:].values\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60, len(inputs)):\n",
    "    X_test.append(inputs[i-60:i, 0:6])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "predicted_price_scaled = model.predict(X_test)\n",
    "\n",
    "predicted_price_scaled_copies = np.repeat(predicted_price_scaled, training_set.shape[1], axis=-1)\n",
    "predicted_price = sc.inverse_transform(predicted_price_scaled_copies)[:, 0]\n",
    "\n",
    "# Visualizing the results\n",
    "plt.plot(df_date_train.index,training_set[:,0], color='green', label='Actual Tesla Stock Price')\n",
    "plt.plot(df_date_test.index,testing_set[:,0], color='red', label='Actual Tesla Stock Price')\n",
    "plt.plot(df_date_test.index,predicted_price, color='blue', label='Predicted Tesla Stock Price')\n",
    "plt.title('Tesla Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Tesla Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327059c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
